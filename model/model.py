# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yggKmX2iScOlYcR55zggt2W-0A3Jw6ly

# SENTIMENT ANALYSIS MODEL FOR DEPLOYMENT IN KENYA'S CONSTRUCTION SECTOR FOR SERVICE CLASSIFICATION
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install transformers datasets evaluate torch scikit-learn

import os
os.environ["WANDB_DISABLED"] = "true"

# For data manipulation and visualization
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# For handling model training
import torch
from sklearn.model_selection import train_test_split
from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
import evaluate

# Check if GPU is available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Using device: {device}')

"""## Importing the datasets"""

english_data = pd.read_csv('/content/drive/MyDrive/datasets/csv/data_english.csv', encoding='latin1')
swahili_data = pd.read_csv('/content/drive/MyDrive/datasets/csv/data_swahili.csv', encoding='latin1')

english_data.head()

english_data.shape

swahili_data.head()

swahili_data.shape

"""### Manipulating the english dataset

The structure needed before training the model should be: Text, Sentiment - similar to the swahili dataset. We shall use the rating to get this structure.
"""

# Check different data and confirm data types
print(english_data.head())
print(english_data.dtypes)

# Print unique data in Ratings column
print(english_data['Ratings'].unique())

english_data['Ratings'] = pd.to_numeric(english_data['Ratings'], errors='coerce')

english_data = english_data.dropna(subset=['Ratings'])

# Change Ratings values from strings to integers
english_data['Ratings'] = english_data['Ratings'].astype(int)

# Assign positive and negative classes to text data based on ratings - ratings of 1 or 2 are classified as regative
english_data['Sentiment'] = english_data['Ratings'].apply(lambda x: 'negative' if x <= 2 else 'positive')

english_data.head()

# Drop "Ratings" column
english_data = english_data.drop(columns=['Ratings'])

"""### Verifying structure of both datasets"""

english_data.head()

swahili_data.head()

"""### Merging the two datasets"""

# Merge english_data and swahili_data into a new dataframe text_data
text_data = pd.concat([english_data, swahili_data], ignore_index=True)

text_data.shape

text_data.head()

text_data.tail()

"""Now we randomise the order of the records to allow our model to encounter random text of either english or swahili as it is training"""

# Randomize the order of records in the text_data dataframe
text_data = text_data.sample(frac=1, random_state=42).reset_index(drop=True)

text_data.head()

# Checking for null values in the merged data frame
text_data.isnull().sum()

"""## Data visualisation"""

# Plotting the distribution of sentiments
plt.figure(figsize=(8, 6))
sns.countplot(data=text_data, x='Sentiment', palette='Set2')
plt.title('Sentiment Distribution')
plt.ylabel('Count')
plt.xlabel('Sentiment')
plt.show()

# Calculate the length of each text entry
text_data['Text_Length'] = text_data['Text'].apply(len)

# Plotting the text length distribution
plt.figure(figsize=(8, 6))
sns.histplot(text_data['Text_Length'], kde=True, color='skyblue')
plt.title('Text Length Distribution')
plt.xlabel('Text Length')
plt.ylabel('Frequency')
plt.show()

!pip install wordcloud

from wordcloud import WordCloud

# Word cloud for all text data
all_text = ' '.join(text_data['Text'])
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)

# Display the word cloud
plt.figure(figsize=(10, 8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for All Text')
plt.show()

# Word cloud for positive sentiment
positive_text = ' '.join(text_data[text_data['Sentiment'] == 'positive']['Text'])
positive_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_text)

plt.figure(figsize=(10, 8))
plt.imshow(positive_wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Positive Sentiment')
plt.show()

# Word cloud for negative sentiment
negative_text = ' '.join(text_data[text_data['Sentiment'] == 'negative']['Text'])
negative_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(negative_text)

plt.figure(figsize=(10, 8))
plt.imshow(negative_wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Negative Sentiment')
plt.show()

"""## Model training"""

# Rename columns for clarity
text_data.rename(columns={'Text': 'text', 'Sentiment': 'label'}, inplace=True)

text_data.head()

"""### Data encoding and splitting"""

# Encode labels (positive -> 1, negative -> 0)
text_data['label'] = text_data['label'].apply(lambda x: 1 if x == 'positive' else 0)

# Train-test split (80-20)
train_df, test_df = train_test_split(text_data, test_size=0.2, random_state=42)

"""### Convert Data to Hugging Face Dataset Format"""

# Convert to Hugging Face Dataset
train_dataset = Dataset.from_pandas(train_df)
test_dataset = Dataset.from_pandas(test_df)

# Load XLM-R tokenizer
tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')

# Tokenization function
def tokenize_function(examples):
    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)

# Tokenize datasets
train_dataset = train_dataset.map(tokenize_function, batched=True)
test_dataset = test_dataset.map(tokenize_function, batched=True)

# Remove unused columns and set format for PyTorch
train_dataset = train_dataset.remove_columns(['text', '__index_level_0__'])
test_dataset = test_dataset.remove_columns(['text', '__index_level_0__'])
train_dataset.set_format(type='torch')
test_dataset.set_format(type='torch')

"""### Load the Pre-trained XLM-RoBERTa Model"""

# Load the pre-trained XLM-R model for sequence classification
model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2).to(device)

"""### Define Evaluation Metrics"""

# Define evaluation metric
f1_metric = evaluate.load("f1")

# Compute metrics function
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return f1_metric.compute(predictions=predictions, references=labels)

"""### Set Training Arguments"""

from transformers import EarlyStoppingCallback

# Training arguments
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=100,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    logging_dir='./logs',
    logging_steps=50,
    load_best_model_at_end=True,
    metric_for_best_model='f1',
    save_total_limit=3,
    learning_rate=2e-5,
    weight_decay=0.01,
    lr_scheduler_type='cosine',
    warmup_steps=500,
    gradient_accumulation_steps=2,
    fp16=True,
    gradient_checkpointing=True  # Save GPU memory
)

# Initialize the Trainer with early stopping
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]
)

# Fine-tune the model
trainer.train()

# Evaluate on test set
results = trainer.evaluate()
print(f"F1 Score: {results['eval_f1']:.4f}")

"""### Confusion matrix for performance visualization

"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Get predictions on the test dataset
test_predictions = trainer.predict(test_dataset)
predicted_labels = test_predictions.predictions.argmax(axis=1)
true_labels = test_predictions.label_ids

# Compute confusion matrix
cm = confusion_matrix(true_labels, predicted_labels, labels=[0, 1])

# Plot confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])
disp.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.show()

"""## Evaluating the model with text examples"""

from transformers import pipeline

# Load the sentiment analysis pipeline with the fine-tuned model
nlp = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)

# Create a mapping from label index to sentiment class
label_map = {0: 'negative', 1: 'positive'}

# Function to test sentiment of a given text
def predict_sentiment(text):
    result = nlp(text)
    sentiment_label = result[0]['label']

    # Convert the label (LABEL_0, LABEL_1) to numeric value and map it to sentiment class
    numeric_label = int(sentiment_label.split('_')[1])  # Extract 0 or 1 from 'LABEL_0', 'LABEL_1'
    sentiment = label_map[numeric_label]
    return sentiment

# Test reviews (Positive and Negative) in both English and Swahili
reviews = {
    "english_positive": "The construction team has been very efficient. The project is ahead of schedule, and the quality of work is exceptional. I am very pleased with the progress.",
    "english_negative": "The construction work has been delayed multiple times, and the quality of materials used is subpar. The team has been unresponsive to our concerns, and I'm frustrated with the progress.",
    "swahili_positive": "Timu ya ujenzi imekuwa na ufanisi mkubwa. Mradi uko mbele ya ratiba, na ubora wa kazi ni wa kipekee. Nina furaha kubwa na maendeleo ya mradi.",
    "swahili_negative": "Kazi ya ujenzi imeshindwa mara kadhaa na ubora wa vifaa vilivyotumika ni hafifu. Timu haijajibu maswali yetu, na nina machungu na maendeleo ya mradi."
}

# Classify each review
for review_type, review_text in reviews.items():
    sentiment = predict_sentiment(review_text)
    print(f"{review_type}: {sentiment}")

# Test reviews (Negative first, Positive second) in both English and Swahili
reviews = {
    "english_negative": "Communication with the team has been poor, and I am dissatisfied with the progress. The construction project has faced several delays, and the quality of work is not up to the mark.",
    "english_positive": "I highly recommend their services. The construction crew did a fantastic job. They completed the project ahead of time, and the quality of the materials used was top-notch.",
    "swahili_negative": "Mawasiliano na timu ni duni, na sina furaha na maendeleo. Mradi wa ujenzi umekumbwa na ucheleweshaji mwingi, na ubora wa kazi sio wa kuridhisha.",
    "swahili_positive": "Napendekeza huduma zao bila shaka. Timu ya ujenzi imefanya kazi nzuri sana. Mradi umekamilika mapema na ubora wa vifaa ulitumika ni bora sana."
}

# Classify each review
for review_type, review_text in reviews.items():
    sentiment = predict_sentiment(review_text)
    print(f"{review_type}: {sentiment}")

# Test reviews (Positive first, Negative second) in both English and Swahili
reviews = {
    "english_positive": "The project was completed with exceptional quality and on time. The team was very professional, and the communication throughout was great. I am extremely satisfied with the final result.",
    "english_negative": "The construction delays were frustrating, and the quality of the work was poor. I had difficulty getting in touch with the team, and the overall experience was disappointing.",
    "swahili_positive": "Timu ya ujenzi imefanya kazi nzuri na mradi umehitimishwa kwa ubora wa kipekee. Mawasiliano yalikuwa bora na nimefurahi sana na matokeo ya mwisho.",
    "swahili_negative": "Ucheleweshaji wa ujenzi ulikuwa wa kutia hasira na ubora wa kazi haukuwa mzuri. Nilikuwa na shida ya kuwasiliana na timu, na uzoefu mzima ulikuwa wa kukatisha tamaa."
}

# Classify each review
for review_type, review_text in reviews.items():
    sentiment = predict_sentiment(review_text)
    print(f"{review_type}: {sentiment}")

"""## Saving the trained model"""

model.save_pretrained('/content/drive/MyDrive/sentiment_model')

tokenizer.save_pretrained('/content/drive/MyDrive/sentiment_model')